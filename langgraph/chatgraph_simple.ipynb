{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangGraph Tutorial\n",
    "\n",
    "this example shows codes for a simple chat graph\n",
    "\n",
    "![](imgs/simple_chat_graph.png)\n",
    "\n",
    "Reference:\n",
    "* https://www.datacamp.com/tutorial/langgraph-tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the State Graph\n",
    "from IPython.display import Image, display\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class State(TypedDict):\n",
    "    # messages have the type \"list\".\n",
    "    # The add_messages function appends messages to the list, rather than overwriting them\n",
    "    messages: Annotated[list, add_messages]\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# get the parent directory of the current file\n",
    "# current_path = os.path.dirname(__file__)\n",
    "current_path = os.getcwd()\n",
    "env_file_path = os.path.join(current_path, \"envs\", \"azure.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Initialize an LLM and add it as a Chatbot node\n",
    "# https://python.langchain.com/docs/integrations/chat/\n",
    "\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "# Load the environment variables from the .env file\n",
    "config = {**dotenv_values(env_file_path)}\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint=config[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    openai_api_version=config[\"AZURE_OPENAI_API_VERSION\"],\n",
    "    azure_deployment=config[\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"],\n",
    "    api_key=config[\"AZURE_OPENAI_API_KEY\"],\n",
    ")\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "'''\n",
    "The first argument is the unique node name\n",
    "The second argument is the function or object that will be called whenever the node is used.'''\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Set edges\n",
    "\n",
    "# Set entry and finish points\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "graph_builder.set_finish_point(\"chatbot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Compile and Visualize the Graph\n",
    "\n",
    "graph = graph_builder.compile()\n",
    "print(type(graph))\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Generator\n",
    "\n",
    "# Flag to control the streaming process\n",
    "streaming = {\"stop\": False}\n",
    "\n",
    "def stop_streaming(b):\n",
    "    streaming[\"stop\"] = True\n",
    "\n",
    "def stream_graph(ai_graph, user_input: str)-> Generator[str, None, None]:\n",
    "    # stream the token from the graph\n",
    "    if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "        # stream a fixed output\n",
    "        yield \"Goodbye!\"\n",
    "        yield \"Exiting the program.\"\n",
    "        stop_streaming(None)\n",
    "    else:\n",
    "        yield f\"User: {user_input}\"\n",
    "        for event in ai_graph.stream({\"messages\": [(\"user\", user_input)]}):\n",
    "            for value in event.values():\n",
    "                yield f\"Assistant: {value['messages'][-1].content}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Create a Text Box for User Input and Output\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# create a text box for user input with a send button\n",
    "user_input = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Type your message here and enter...',\n",
    "    description='User input:',\n",
    "    disabled=False,\n",
    "    layout=widgets.Layout(width='100%', height='40px', style={'description_width': 'initial'}),\n",
    ")\n",
    "\n",
    "# replace the widgets.Textarea with a text box for user output on the widget output area\n",
    "output_text = widgets.Output(\n",
    "    layout=widgets.Layout(\n",
    "        width='100%',\n",
    "        height='300px',\n",
    "        overflow='auto',  # Ensure scrollbars appear if content overflows\n",
    "        # style={'description_width': 'initial', 'white-space': 'pre-wrap'},  # Enable text wrapping\n",
    "        style={'description_width': 'initial', 'white-space': 'pre-wrap'},  # Enable text wrapping\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "# Flag to control the streaming process\n",
    "streaming = {\"stop\": False}\n",
    "\n",
    "# function to handle user input and update the output\n",
    "def handle_user_input(change):\n",
    "    if change['name'] == 'value' and change['type'] == 'change' and change['new'] != '':\n",
    "        # clear the output area\n",
    "        # clear_output(wait=True)\n",
    "        # get the user input\n",
    "        user_input_value = change['new']\n",
    "        # clear the user input text box\n",
    "        user_input.value = ''\n",
    "\n",
    "        # Reset the stop flag\n",
    "        # streaming[\"stop\"] = False\n",
    "\n",
    "        # stream the graph with the user input\n",
    "        output_stream = stream_graph(graph, user_input_value)\n",
    "        \n",
    "        # iterate over the output stream and update the output text box with the new value\n",
    "        with output_text:\n",
    "            for value in output_stream:\n",
    "                if streaming[\"stop\"]:\n",
    "                    print(\"Streaming stopped.\")\n",
    "                    break\n",
    "                print(value)\n",
    "            print(\"\\n\")  # Add a newline for better readability\n",
    "\n",
    "\n",
    "# observe changes in the user_input widget\n",
    "user_input.continuous_update = False  # Disable continuous updates to avoid multiple triggers\n",
    "user_input.observe(handle_user_input, names='value')\n",
    "\n",
    "\n",
    "# Deprecate the on_submit and replace it with the observe method\n",
    "# def on_send_button_click(b):\n",
    "#     # clear the output area\n",
    "#     clear_output(wait=True)\n",
    "#     # get the user input\n",
    "#     user_input_value = user_input.value\n",
    "#     # clear the user input text box\n",
    "#     user_input.value = ''\n",
    "\n",
    "#     # stream the graph with the user input\n",
    "#     output_stream = stream_graph(graph, user_input_value)\n",
    "    \n",
    "#     # iterate over the output stream and update the output text box with the new value\n",
    "#     with output_text:\n",
    "#         # clear the output text box\n",
    "#         # output_text.clear_output(wait=True)\n",
    "        \n",
    "#         for value in output_stream:\n",
    "#             print(value)\n",
    "#         print(\"\\n\")  # Add a newline for better readability\n",
    "# user_input.on_submit(on_send_button_click)\n",
    "\n",
    "\n",
    "# display the text box and output area\n",
    "display(user_input)\n",
    "display(output_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents3.12pip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
