# huggingface_hub==0.25.2
huggingface_hub==0.26.2

# transformers==4.45.2
transformers==4.46.3

# urllib3==1.26.16
# urllib3>=2.0.7

# jsonschema==4.19.0
jsonschema==4.23.0
# for showing download widget in jupyter notebook
# ipywidgets==8.1.3
ipywidgets==8.1.5
# for python script input arg generation
click==8.1.7

# pypdf==4.3.1
# pypdf==5.0.1
pypdf==5.1.0

# torch==2.1.2
# torchaudio==2.1.2
# torchvision==0.16.2
# fastai==2.7.13

# Testing MPS memory features
# torch==2.3.1
# torchaudio==2.3.1
# torchvision==0.18.1

# torch==2.4.1
# torchaudio==2.4.1
# torchvision==0.19.1

torch==2.5.1
torchaudio==2.5.1
torchvision==0.20.1


# flash attention cuda package not for MPS
# flash-attn==2.6.3

# vision library
# fastai==2.7.14 # fastai depends on torch version
# fastai==2.7.15

## langchain LLM
# langchain==0.2.16
# langchain-community==0.2.16
# langchain-huggingface==0.0.3
# langchainhub==0.1.21
# langchain-ollama==0.1.3

# langchain==0.3.7
# langchain-community==0.3.7
# langchain-huggingface==0.1.2
# langchainhub==0.1.21
# langchain-ollama==0.2.0

langchain==0.3.8
langchain-community==0.3.8
langchain-huggingface==0.1.2
langchainhub==0.1.21
langchain-ollama==0.2.0

# need Pydantic 1.10.12 to better evaluate typehints
# https://github.com/langchain-ai/langchain/issues/8577#issuecomment-1663249273
# pydantic==1.10.13
# fastapi for autogen-studio doesn't support pydantic 2.9.0 yet
# you need to fix to this version
pydantic==2.8.2
# pydantic==2.9.2

# docarray doesn't work with pydantic 2.xx, pydantic_core is installed with 2.xx, must be removed. 
# pydantic>=1.10.13 # typehints
# unstructured==0.15.0  # for langchain S3DirectoryLoader to load txt file
# unstructured==0.15.14
unstructured==0.16.5

# for langchain vectorestore embedding model
# sentence-transformers==3.2.1
sentence-transformers==3.3.1
# langchain DocArrayInMemorySearch nned docarray
docarray==0.40.0

# s3 client
# boto3==1.35.63
boto3==1.35.70

## GPU/MPS training speed up for tranformers
# accelerate==1.0.1
accelerate==1.1.1

# peft==0.13.0
peft==0.13.2

# For tensorflow and macosx m1 gput
# backend of pretrained google model from tensorflow hub are on Kaggle
tensorflow==2.18.0 
# no metal for windows
# tensorflow-metal==1.1.0
tensorflow-hub==0.16.1


## install huggingface datasets for fine-tuning on MPS backend device using torch
# datasets==3.0.2
datasets==3.1.0
# huggingface evaluate for evaluate the fine-tuned model
# evaluate==0.4.2
evaluate==0.4.3

# transformer model quantization
bitsandbytes==0.42.0
# bitsandbytes==0.44.1

# install your own gitlab package 
# --index-url https://gitlab.lrz.de/api/v4/projects/150553/packages/pypi/simple
# --trusted-host https://gitlab.lrz.de
applyllm==0.0.7
# faiss-cpu==1.9.0
faiss-cpu==1.9.0.post1

# For Stable DiffusionPipeline
# diffusers==0.30.3
diffusers==0.31.0
sentencepiece==0.2.0

# open ai
# openai==1.54.4
# openai==1.55.1
openai==1.57.2

# autogenstudio
# https://github.com/microsoft/autogen/tree/main/samples/apps/autogen-studio
# autogenstudio==0.1.4
# pyautogen==0.2.35
autogenstudio==0.1.5
autogen-agentchat==0.2.39
# autogen-agentchat~=0.2
# pyautogen>=0.2.35
# pyautogen==0.4
# pyautogen==0.3.2

#phi 
# flash_attn==2.5.8
einops==0.8.0
# triton==2.3.1
# tritonclient==2.47.0
# pytest==8.2.2
python-dotenv==1.0.1

# UI tool for building AI agent

# promptflow==1.16.1
# promptflow-tools==1.4.0
# azure-identity==1.19.0
# # open telemetry spec for trace feature in LangChain and AutoGen 
# promptflow-tracing==1.16.1 

promptflow==1.16.2
promptflow-tools==1.4.0
azure-identity==1.19.0
# open telemetry spec for trace feature in LangChain and AutoGen 
promptflow-tracing==1.16.2

# semantic-kernel==1.12.1
# semantic-kernel==1.14.0
# semantic-kernel==1.15.0
# semantic-kernel==1.16.0
semantic-kernel==1.17.0