{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "this notebook demos example of using llm in a MPS backend (apple silicon GPU) using torch 2.x\n",
    "\n",
    "Referece:\n",
    "* torch 2.x MPS Backend: https://pytorch.org/docs/stable/notes/mps.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.6\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import applyllm as apl\n",
    "\n",
    "print(apl.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS is available\n",
      "mps\n"
     ]
    }
   ],
   "source": [
    "# check that MPS is availabe (Metal Performance Shaders)\n",
    "if not torch.backends.mps.is_available():\n",
    "    print(\"MPS is not available\")\n",
    "else:\n",
    "    print(\"MPS is available\")\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    print(mps_device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/yingding/MODELS\n"
     ]
    }
   ],
   "source": [
    "from applyllm.accelerators import (\n",
    "    DirectorySetting,\n",
    "    TokenHelper as th,\n",
    ")\n",
    "    \n",
    "dir_mode_map = {\n",
    "    \"kf_notebook\": DirectorySetting(),\n",
    "    \"mac_local\": DirectorySetting(home_dir=\"/Users/yingding\", transformers_cache_home=\"MODELS\", huggingface_token_file=\"MODELS/.huggingface_token\"),\n",
    "}\n",
    "\n",
    "model_map = {\n",
    "    \"llama7B-chat\":     \"meta-llama/Llama-2-7b-chat-hf\",\n",
    "    \"llama13B-chat\" :   \"meta-llama/Llama-2-13b-chat-hf\",\n",
    "    \"llama70B-chat\" :   \"meta-llama/Llama-2-70b-chat-hf\",\n",
    "    \"mistral7B-01\":     \"mistralai/Mistral-7B-v0.1\",\n",
    "    \"mistral7B-inst02\": \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    \"mixtral8x7B-01\":   \"mistralai/Mixtral-8x7B-v0.1\",\n",
    "    \"mixtral8x7B-inst01\":   \"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    "    \"gemma7b-it\": \"google/gemma-7b-it\",\n",
    "    \"gemma7b\" : \"google/gemma-7b\",\n",
    "    \"gemma7b-it-1.1\": \"google/gemma-1.1-7b-it\",\n",
    "    \"gemma2b-it\": \"google/gemma-2b-it\",\n",
    "    \"gemma2b\" : \"google/gemma-2b\",\n",
    "    \"gemma2b-it-1.1\": \"google/gemma-1.1-2b-it\",\n",
    "}\n",
    "\n",
    "default_model_type = \"mistral7B-01\"\n",
    "default_dir_mode = \"mac_local\"\n",
    "\n",
    "dir_setting = dir_mode_map[default_dir_mode]\n",
    "\n",
    "os.environ[\"WORLD_SIZE\"] = \"1\" \n",
    "os.environ['XDG_CACHE_HOME'] = dir_setting.get_cache_home()\n",
    "\n",
    "print(os.environ['XDG_CACHE_HOME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.39.3\n",
      "2.2.2\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "\n",
    "print(transformers.__version__)\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose LLM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "google/gemma-1.1-7b-it\n"
     ]
    }
   ],
   "source": [
    "# model_type = default_model_type\n",
    "# model_type = \"gemma7b-it\"\n",
    "model_type = \"gemma7b-it-1.1\"\n",
    "# model_type = \"gemma2b-it\"\n",
    "# model_type = \"gemma2b-it-1.1\"\n",
    "# model_type = \"mistral7B-inst02\"\n",
    "# model_type = \"llama7B-chat\"\n",
    "# model_type = \"llama13B-chat\"\n",
    "\n",
    "model_name = model_map.get(model_type, default_model_type)\n",
    "print(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fast tokenizer\n",
    "\n",
    "* https://github.com/huggingface/transformers/issues/23889#issuecomment-1584090357"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load LLM Model and then Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface token is NOT needed\n",
      "token_kwargs: {}\n",
      "model_kwargs: {'torch_dtype': torch.float16, 'device_map': 'mps', 'max_length': None}\n",
      "pipeline_kwargs: {'torch_dtype': torch.float16, 'device_map': 'mps', 'max_length': None, 'task': 'text-generation', 'max_new_tokens': 200, 'do_sample': True, 'temperature': 0.001, 'top_k': 3, 'top_p': 0.85, 'framework': 'pt', 'return_full_text': False, 'add_special_tokens': True}\n"
     ]
    }
   ],
   "source": [
    "from applyllm.pipelines import (\n",
    "    ModelCatalog,\n",
    "    KwargsBuilder\n",
    ")\n",
    "token_kwargs = th.gen_token_kwargs(model_type=model_type, dir_setting=dir_setting)\n",
    "print(f\"token_kwargs: {token_kwargs}\")\n",
    "\n",
    "# data_type = torch.bfloat16\n",
    "data_type = torch.float16\n",
    "device_map = \"mps\" # \"auto\"  \n",
    "# auto caste not working for mps 4.38.2\n",
    "# https://github.com/huggingface/transformers/issues/29431 \n",
    "\n",
    "# mixtral model has no max_new_tokens limit, so it is not set here.\n",
    "model_kwargs = {\n",
    "    \"torch_dtype\": data_type, #bfloat16 is not supported on MPS backend, float16 only on GPU accelerator\n",
    "    # torch_dtype=torch.float32,\n",
    "    # max_length=MAX_LENGTH,\n",
    "    \"device_map\": device_map,\n",
    "    \"max_length\" : None, # remove the total length of the generated response\n",
    "}\n",
    "print(f\"model_kwargs: {model_kwargs}\")\n",
    "\n",
    "# set the transformers.pipeline kwargs\n",
    "# the torch_dtype shall be set both for the model and the pipeline, due to a transformer issue.\n",
    "# otherwise it will cause unnecessary more memory usage in the pipeline of transformers\n",
    "# https://github.com/huggingface/transformers/issues/28817\n",
    "# https://github.com/mlflow/mlflow/pull/10979\n",
    "\n",
    "# Set transformers.pipeline only to return generated text return_full_text=False\n",
    "# https://github.com/huggingface/transformers/issues/17117#issuecomment-1120809167\n",
    "pipeline_kwargs = {\n",
    "    \"task\": \"text-generation\",\n",
    "    \"max_new_tokens\" : 200,\n",
    "    \"do_sample\" : True, # do_sample True is required for temperature\n",
    "    \"temperature\" : 0.001, \n",
    "    \"device_map\" : device_map, # use the MPS device if available\n",
    "    \"top_k\": 3,\n",
    "    \"top_p\": 0.85, #0.95\n",
    "    # \"num_return_sequences\": 1,\n",
    "    \"framework\": \"pt\", # use pytorch as framework\n",
    "    \"return_full_text\": False, # return only the generated text, not the input text with the generated text\n",
    "}\n",
    "\n",
    "gemma_pipeline_kwargs = {\n",
    "    \"add_special_tokens\": True,\n",
    "    \"torch_dtype\": data_type,\n",
    "}\n",
    "\n",
    "# pipeline_kwargs override the model_kwargs during the merge\n",
    "pipeline_kwargs = KwargsBuilder([model_kwargs]).override(pipeline_kwargs).build()\n",
    "\n",
    "if model_name.startswith(ModelCatalog.GOOGLE_FAMILY):\n",
    "    pipeline_kwargs = KwargsBuilder([pipeline_kwargs]).override(gemma_pipeline_kwargs).build()\n",
    "\n",
    "print(f\"pipeline_kwargs: {pipeline_kwargs}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max memory to offload parts of LLM model to the CPU memory\n",
    "* https://huggingface.co/docs/accelerate/concept_guides/big_model_inference#designing-a-device-map\n",
    "\n",
    "Note:\n",
    "* Max Memory offload to CPU is CUDA implementation only\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f4703686a4047d79972d00d80d37009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "executed: load_model() python function\n",
      "walltime: 19.388441801071167 in secs.\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from applyllm.utils import time_func\n",
    "from applyllm.pipelines import ModelConfig, LocalCausalLMConfig\n",
    "\n",
    "\n",
    "base_lm_config = ModelConfig(\n",
    "  model_config = {\n",
    "    \"pretrained_model_name_or_path\": model_name,\n",
    "    \"device_map\": device_map,\n",
    "  }\n",
    ")\n",
    "\n",
    "# No bitsandbytes qunatization support for MPS backend yet, set quantized to False\n",
    "kwargs = {\n",
    "  \"quantized\": False,\n",
    "  \"model_config\": base_lm_config.get_config(),\n",
    "  \"quantization_config\": {\n",
    "    \"quantization_config\": transformers.BitsAndBytesConfig(\n",
    "      load_in_4bit=True,\n",
    "      bnb_4bit_quant_type='nf4',\n",
    "      bnb_4bit_use_double_quant=True,\n",
    "      bnb_4bit_compute_dtype=torch.bfloat16\n",
    "      )\n",
    "    },\n",
    "    \"trust_remote_code\": True,\n",
    "}\n",
    "\n",
    "lm_config = LocalCausalLMConfig(**kwargs)\n",
    "\n",
    "@time_func\n",
    "def load_model():\n",
    "  return AutoModelForCausalLM.from_pretrained(    \n",
    "    **lm_config.get_config(),\n",
    "    **token_kwargs,  \n",
    "  )\n",
    "\n",
    "model = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_kwargs = {\n",
    "    \"model_config\": {\n",
    "        \"pretrained_model_name_or_path\": model_name,\n",
    "        \"device\": \"cpu\",\n",
    "        # \"device_map\": \"auto\", # put to GPU if GPU is available\n",
    "        # \"max_position_embeddings\": MAX_LENGTH,\n",
    "        # \"max_length\": MAX_LENGTH,\n",
    "    },\n",
    "}\n",
    "tokenizer_config = ModelConfig(**tokenizer_kwargs)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    **tokenizer_config.get_config(),\n",
    "    **token_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GemmaTokenizerFast(name_or_path='google/gemma-1.1-7b-it', vocab_size=256000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<bos>', 'eos_token': '<eos>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<start_of_turn>', '<end_of_turn>']}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<eos>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"<bos>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t4: AddedToken(\"<mask>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t5: AddedToken(\"<2mass>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t6: AddedToken(\"[@BOS@]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t7: AddedToken(\"<unused0>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t8: AddedToken(\"<unused1>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t9: AddedToken(\"<unused2>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t10: AddedToken(\"<unused3>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t11: AddedToken(\"<unused4>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t12: AddedToken(\"<unused5>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t13: AddedToken(\"<unused6>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t14: AddedToken(\"<unused7>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t15: AddedToken(\"<unused8>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t16: AddedToken(\"<unused9>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t17: AddedToken(\"<unused10>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t18: AddedToken(\"<unused11>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t19: AddedToken(\"<unused12>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20: AddedToken(\"<unused13>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t21: AddedToken(\"<unused14>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t22: AddedToken(\"<unused15>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t23: AddedToken(\"<unused16>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t24: AddedToken(\"<unused17>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t25: AddedToken(\"<unused18>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t26: AddedToken(\"<unused19>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t27: AddedToken(\"<unused20>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t28: AddedToken(\"<unused21>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t29: AddedToken(\"<unused22>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t30: AddedToken(\"<unused23>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t31: AddedToken(\"<unused24>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t32: AddedToken(\"<unused25>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t33: AddedToken(\"<unused26>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t34: AddedToken(\"<unused27>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t35: AddedToken(\"<unused28>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t36: AddedToken(\"<unused29>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t37: AddedToken(\"<unused30>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t38: AddedToken(\"<unused31>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t39: AddedToken(\"<unused32>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t40: AddedToken(\"<unused33>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t41: AddedToken(\"<unused34>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t42: AddedToken(\"<unused35>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t43: AddedToken(\"<unused36>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t44: AddedToken(\"<unused37>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t45: AddedToken(\"<unused38>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t46: AddedToken(\"<unused39>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t47: AddedToken(\"<unused40>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t48: AddedToken(\"<unused41>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t49: AddedToken(\"<unused42>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t50: AddedToken(\"<unused43>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t51: AddedToken(\"<unused44>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t52: AddedToken(\"<unused45>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t53: AddedToken(\"<unused46>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t54: AddedToken(\"<unused47>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t55: AddedToken(\"<unused48>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t56: AddedToken(\"<unused49>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t57: AddedToken(\"<unused50>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t58: AddedToken(\"<unused51>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t59: AddedToken(\"<unused52>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t60: AddedToken(\"<unused53>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t61: AddedToken(\"<unused54>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t62: AddedToken(\"<unused55>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t63: AddedToken(\"<unused56>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t64: AddedToken(\"<unused57>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t65: AddedToken(\"<unused58>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t66: AddedToken(\"<unused59>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t67: AddedToken(\"<unused60>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t68: AddedToken(\"<unused61>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t69: AddedToken(\"<unused62>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t70: AddedToken(\"<unused63>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t71: AddedToken(\"<unused64>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t72: AddedToken(\"<unused65>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t73: AddedToken(\"<unused66>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t74: AddedToken(\"<unused67>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t75: AddedToken(\"<unused68>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t76: AddedToken(\"<unused69>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t77: AddedToken(\"<unused70>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t78: AddedToken(\"<unused71>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t79: AddedToken(\"<unused72>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t80: AddedToken(\"<unused73>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t81: AddedToken(\"<unused74>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t82: AddedToken(\"<unused75>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t83: AddedToken(\"<unused76>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t84: AddedToken(\"<unused77>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t85: AddedToken(\"<unused78>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t86: AddedToken(\"<unused79>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t87: AddedToken(\"<unused80>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t88: AddedToken(\"<unused81>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t89: AddedToken(\"<unused82>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t90: AddedToken(\"<unused83>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t91: AddedToken(\"<unused84>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t92: AddedToken(\"<unused85>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t93: AddedToken(\"<unused86>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t94: AddedToken(\"<unused87>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t95: AddedToken(\"<unused88>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t96: AddedToken(\"<unused89>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t97: AddedToken(\"<unused90>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t98: AddedToken(\"<unused91>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t99: AddedToken(\"<unused92>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t100: AddedToken(\"<unused93>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t101: AddedToken(\"<unused94>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t102: AddedToken(\"<unused95>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t103: AddedToken(\"<unused96>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t104: AddedToken(\"<unused97>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t105: AddedToken(\"<unused98>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t106: AddedToken(\"<start_of_turn>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t107: AddedToken(\"<end_of_turn>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t108: AddedToken(\"\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t109: AddedToken(\"\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t110: AddedToken(\"\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t111: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t112: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t113: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t114: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t115: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t116: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t117: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t118: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t119: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t120: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t121: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t122: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t123: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t124: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t125: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t126: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t127: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t128: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t129: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t130: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t131: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t132: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t133: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t134: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t135: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t136: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t137: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t138: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t139: AddedToken(\"▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t140: AddedToken(\"▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t141: AddedToken(\"▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t142: AddedToken(\"▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t143: AddedToken(\"▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t144: AddedToken(\"▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t145: AddedToken(\"▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t146: AddedToken(\"▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t147: AddedToken(\"▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t148: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t149: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t150: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t152: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t153: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t154: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t155: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t156: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t157: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t158: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t159: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t160: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t161: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t162: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t163: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t164: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t165: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t166: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t167: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t168: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t169: AddedToken(\"<table>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t170: AddedToken(\"<caption>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t171: AddedToken(\"<thead>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t172: AddedToken(\"<tbody>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t173: AddedToken(\"<tfoot>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t174: AddedToken(\"<tr>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t175: AddedToken(\"<th>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t176: AddedToken(\"<td>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t177: AddedToken(\"</table>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t178: AddedToken(\"</caption>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t179: AddedToken(\"</thead>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t180: AddedToken(\"</tbody>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t181: AddedToken(\"</tfoot>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t182: AddedToken(\"</tr>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t183: AddedToken(\"</th>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t184: AddedToken(\"</td>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t185: AddedToken(\"<h1>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t186: AddedToken(\"<h2>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t187: AddedToken(\"<h3>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t188: AddedToken(\"<h4>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t189: AddedToken(\"<h5>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t190: AddedToken(\"<h6>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t191: AddedToken(\"<blockquote>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t192: AddedToken(\"</h1>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t193: AddedToken(\"</h2>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t194: AddedToken(\"</h3>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t195: AddedToken(\"</h4>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t196: AddedToken(\"</h5>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t197: AddedToken(\"</h6>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t198: AddedToken(\"</blockquote>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t199: AddedToken(\"<strong>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t200: AddedToken(\"<em>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t201: AddedToken(\"<b>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t202: AddedToken(\"<i>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t203: AddedToken(\"<u>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t204: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t205: AddedToken(\"<sub>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t206: AddedToken(\"<sup>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t207: AddedToken(\"<code>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t208: AddedToken(\"</strong>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t209: AddedToken(\"</em>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t210: AddedToken(\"</b>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t211: AddedToken(\"</i>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t212: AddedToken(\"</u>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t213: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t214: AddedToken(\"</sub>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t215: AddedToken(\"</sup>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t216: AddedToken(\"</code>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing token\n",
    "* https://huggingface.co/docs/tokenizers/pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "google/gemma-1.1-7b-it\n"
     ]
    }
   ],
   "source": [
    "print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from applyllm.pipelines import (\n",
    "    ModelCatalog,\n",
    "    PromptHelper\n",
    ")\n",
    "\n",
    "model_info = ModelCatalog.get_model_info(model_name)\n",
    "prompt_helper = PromptHelper(model_info)\n",
    "\n",
    "if model_info.model_family == ModelCatalog.GOOGLE_FAMILY:\n",
    "    query = \"\"\"BEGIN EXAMPLE\n",
    "Q: Roger has 3 tennis balls. He buys 2 more cans of tennis balls. Each can has 4 tennis balls. How many tennis balls does he have now?\n",
    "A: Roger started with 3 balls. 2 cans of 4 tennis balls each is 8 tennis balls. 3 + 8 = 11. The answer is 11.\n",
    "END EXAMPLE\n",
    "\n",
    "Your turn:            \n",
    "Q: The cafeteria had 23 apples. If they used 20 to make lunch and bought 6 more, how many apples do they have? \n",
    "\"\"\"\n",
    "    inputs=[prompt_helper.gen_prompt(query)]\n",
    "else: \n",
    "    inputs=[\"\"\"\n",
    "Q: Roger has 3 tennis balls. He buys 2 more cans of tennis balls. Each can has 4 tennis balls. How many tennis balls does he have now?\n",
    "A: Roger started with 3 balls. 2 cans of 4 tennis balls each is 8 tennis balls. 3 + 8 = 11. The answer is 11.\n",
    "Q: The cafeteria had 23 apples. If they used 20 to make lunch and bought 6 more, how many apples do they have?\n",
    "\"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "253\n",
      "[2, 106, 1645, 108, 2045, 708, 476, 10055, 235269, 62275, 578, 10406, 20409, 235265, 108, 24367, 3448, 685, 1707, 3948, 685, 3077, 2177, 573, 4807, 2793, 4646, 235265, 108, 6922, 10523, 1412, 1297, 3448, 573, 2872, 3631, 235269, 66004, 578, 749, 780, 791, 1089, 2793, 1452, 573, 3448, 603, 3015, 235265, 108, 6922, 10523, 1412, 1297, 614, 2793, 578, 780, 3707, 1089, 19319, 235269, 26353, 3782, 235269, 689, 1156, 93846, 235265, 109, 2495, 476, 2872, 1721, 780, 1501, 5229, 689, 603, 780, 2251, 38303, 63269, 235269, 10200, 3165, 5918, 576, 39534, 2775, 780, 5112, 235265, 1927, 692, 1453, 235303, 235251, 1230, 573, 3448, 577, 476, 2872, 235269, 3743, 1453, 235303, 235251, 4638, 1566, 2113, 235265, 6372, 1931, 590, 1453, 235303, 235251, 1230, 235265, 109, 26093, 90412, 108, 235368, 235292, 23627, 919, 235248, 235304, 22560, 20980, 235265, 1315, 58015, 235248, 235284, 978, 34252, 576, 22560, 20980, 235265, 9573, 798, 919, 235248, 235310, 22560, 20980, 235265, 2250, 1767, 22560, 20980, 1721, 693, 791, 1490, 235336, 108, 235280, 235292, 23627, 4604, 675, 235248, 235304, 20980, 235265, 235248, 235284, 34252, 576, 235248, 235310, 22560, 20980, 1853, 603, 235248, 235321, 22560, 20980, 235265, 235248, 235304, 963, 235248, 235321, 589, 235248, 235274, 235274, 235265, 714, 3448, 603, 235248, 235274, 235274, 235265, 108, 3919, 90412, 109, 6922, 2894, 235292, 149, 108, 235368, 235292, 714, 105257, 1093, 235248, 235284, 235304, 34188, 235265, 1927, 984, 1671, 235248, 235284, 235276, 577, 1501, 13955, 578, 8989, 235248, 235318, 978, 235269, 1368, 1767, 34188, 749, 984, 791, 235336, 235248, 109, 107, 108, 106, 2516, 108]\n"
     ]
    }
   ],
   "source": [
    "input_test_encoded = tokenizer.encode(inputs[0])\n",
    "print(f\"{len(input_test_encoded)}\")\n",
    "print(input_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos><start_of_turn>user\n",
      "You are a helpful, respectful and honest assistant.\n",
      "Always answer as helpfully as possible using the context text provided.\n",
      "Your answers should only answer the question once, concise and do not have any text after the answer is done.\n",
      "Your answers should only be text and not include any HTML, bullet points, or other markup.\n",
      "\n",
      "If a question does not make sense or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information. Just say I don't know.\n",
      "\n",
      "BEGIN EXAMPLE\n",
      "Q: Roger has 3 tennis balls. He buys 2 more cans of tennis balls. Each can has 4 tennis balls. How many tennis balls does he have now?\n",
      "A: Roger started with 3 balls. 2 cans of 4 tennis balls each is 8 tennis balls. 3 + 8 = 11. The answer is 11.\n",
      "END EXAMPLE\n",
      "\n",
      "Your turn:            \n",
      "Q: The cafeteria had 23 apples. If they used 20 to make lunch and bought 6 more, how many apples do they have? \n",
      "\n",
      "<end_of_turn>\n",
      "<start_of_turn>model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response_test_decoded = tokenizer.decode(input_test_encoded)\n",
    "print(response_test_decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'torch_dtype': torch.float16, 'device_map': 'mps', 'max_length': None, 'task': 'text-generation', 'max_new_tokens': 200, 'do_sample': True, 'temperature': 0.001, 'top_k': 3, 'top_p': 0.85, 'framework': 'pt', 'return_full_text': False, 'add_special_tokens': True}\n"
     ]
    }
   ],
   "source": [
    "# bitsandbytes quantization does not work with MPS backend\n",
    "print(pipeline_kwargs)\n",
    "\n",
    "# transformer pipeline kwargs\n",
    "tp_kwargs = {\n",
    "    \"model\": model,\n",
    "    \"tokenizer\": tokenizer,\n",
    "}\n",
    "\n",
    "tp_config = ModelConfig(model_config = tp_kwargs)\n",
    "\n",
    "generator = transformers.pipeline(\n",
    "    **tp_config.get_config(),\n",
    "    **pipeline_kwargs,\n",
    "    **token_kwargs,\n",
    "    # **compression_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Install autopep8 or black extension in VSCode\n",
    "`shift + opt + F` to auto format python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Allocated memory : 32.937866 GB\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "from applyllm.accelerators import AcceleratorStatus\n",
    "\n",
    "gpu_status = AcceleratorStatus.create_accelerator_status()\n",
    "gpu_status.gpu_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.4'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pydantic\n",
    "pydantic.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "\n",
    "\n",
    "llm = HuggingFacePipeline(\n",
    "    pipeline=generator \n",
    ")\n",
    "\n",
    "template = prompt_helper.gen_prompt(\"{input}\")\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"input\"])\n",
    "\n",
    "\n",
    "@time_func\n",
    "def chat(input) -> str:\n",
    "    \"\"\"\n",
    "    Args: \n",
    "        input: str - the input text to chat with the model, e.g. inputs[0]\n",
    "    \"\"\"\n",
    "    llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    # print(repr(llm_chain))\n",
    "    dict_response = llm_chain.invoke(input={\"input\": input})\n",
    "    return dict_response.get(\"text\", \"\")\n",
    "\n",
    "# pprint(response, indent=0, width=100)\n",
    "\n",
    "# response = chat(input=inputs[0])\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "executed: chat() python function\n",
      "walltime: 9.593132019042969 in secs.\n",
      "====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "repeat = 1\n",
    "for i in range(repeat):\n",
    "    response = chat(input=inputs[0])\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "def clear_mps_memory(tokenizer, generator):\n",
    "    \"\"\"clear the MPS memory\"\"\"\n",
    "    if tokenizer is not None:\n",
    "        del tokenizer\n",
    "    if generator is not None:\n",
    "        # need to move the model to cpu before delete.\n",
    "        generator.model.cpu()\n",
    "        del generator\n",
    "    gc.collect()\n",
    "    torch.mps.empty_cache()\n",
    "    # report the GPU usage\n",
    "    gpu_status.gpu_usage()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Allocated memory : 34.070023 GB\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "gpu_status.gpu_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs2 = [\"Which animal is the largest mammal?\"]\n",
    "# inputs2 = [\"Can you tell me something about chron's disease?\"]\n",
    "\n",
    "# hallucination https://www.findacode.com/snomed/34000006--crohns-disease.html\n",
    "\n",
    "# real answer is 34000006, probably need a RAG \n",
    "# inputs2 = [\"Which snomed ct code has chron's disease?\"]\n",
    "\n",
    "# inputs2 = [\"Can you tell me more about the company nordcloud?\"]\n",
    "inputs2 = [\"Can you tell me more about the company nordcloud in munich?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "executed: chat() python function\n",
      "walltime: 5.8323140144348145 in secs.\n",
      "====================\n",
      "I am unable to provide information regarding specific companies or their details. Please provide the relevant company or query for more information.\n"
     ]
    }
   ],
   "source": [
    "print(chat(input=inputs2[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define agent\n",
    "* https://python.langchain.com/docs/modules/agents/\n",
    "* https://python.langchain.com/docs/modules/agents/quick_start/\n",
    "* https://python.langchain.com/docs/modules/agents/how_to/custom_agent/\n",
    "\n",
    "## Gemma with custom langchain tool \n",
    "* https://github.com/Ashufet/LangChain_ReAct-Agent-with-Function-Calling_Ollama-Gemma-LLM_LangSmith\n",
    "* ReAct Agent: https://www.youtube.com/watch?v=exYUJcz4uZs\n",
    "\n",
    "## Ollama local host endpoint with LangChain\n",
    "* https://medium.com/the-constellar-digital-technology-blog/geek-out-time-play-with-langchain-2-locally-with-gemma-96c6ca370649\n",
    "\n",
    "## ReAct Agent\n",
    "* https://python.langchain.com/docs/modules/agents/agent_types/react/\n",
    "\n",
    "## Retrieval Agent examples\n",
    "* https://github.com/pinecone-io/examples/blob/master/learn/generation/langchain/handbook/08-langchain-retrieval-agent.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model_map = {\n",
    "    \"sentence-transformers\": \"sentence-transformers/all-MiniLM-L12-v2\", # 384\n",
    "    \"baai\" : \"BAAI/bge-base-en-v1.5\" # 768 embedding dims\n",
    "}\n",
    "\n",
    "embed_model_vendor = \"sentence-transformers\"\n",
    "# embed_model_vendor = \"baai\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model_name = embed_model_map[embed_model_vendor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelConfig(model_config={'model_name': 'sentence-transformers/all-MiniLM-L12-v2', 'model_kwargs': {'device': 'cpu'}, 'encode_kwargs': {'normalize_embeddings': True}})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "model_config = {\n",
    "    \"model_name\" : embed_model_name,\n",
    "    \"model_kwargs\": {'device': 'cpu'},\n",
    "    \"encode_kwargs\": {'normalize_embeddings': True}\n",
    "}\n",
    "embed_config = ModelConfig(model_config=model_config)\n",
    "\n",
    "# is downloaded at \"{MODEL_CACHE_DIR}/models/torch/sentence_transformer\" folder\n",
    "embed_model = HuggingFaceEmbeddings(\n",
    "    **embed_config.get_config()\n",
    ")\n",
    "\n",
    "embed_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from applyllm.utils import token_size\n",
    "from applyllm.pipelines import ModelConfig\n",
    "\n",
    "MAX_POSITION_EMBEDDINGS = 1000 # 4096\n",
    "CHUNK_SIZE = (MAX_POSITION_EMBEDDINGS // 1000) * 1000\n",
    "\n",
    "# Config splitter\n",
    "model_config = {\n",
    "    # Set a really small chunk size, just to show.\n",
    "    \"chunk_size\": CHUNK_SIZE,\n",
    "    \"chunk_overlap\": 200,\n",
    "    \"length_function\": token_size, # len,\n",
    "    \"is_separator_regex\": False,\n",
    "}\n",
    "\n",
    "splitter_config = ModelConfig(model_config=model_config)\n",
    "\n",
    "loader = WebBaseLoader(\"https://nordcloud.com/company/\")\n",
    "docs = loader.load()\n",
    "documents = RecursiveCharacterTextSplitter(\n",
    "    **splitter_config.get_config()\n",
    ").split_documents(docs)\n",
    "\n",
    "vector = FAISS.from_documents(documents, embed_model)\n",
    "retriever = vector.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=\"Proud to be cloud native.\\n\\n\\n\\n\\n\\n\\n\\n\\nWhy NordcloudWe help you use the cloud to become stronger, fitter and faster.\\nLearn more \\n\\nOur ApproachWe empower your business to drive value, velocity and growth with the public cloud.\\nLearn more \\n\\n\\n\\n\\n\\nCompany Timeline. \\n\\n\\n\\n2006A cloud-native infrastructure and web application development company is born in Finland!\\n2011Nordcloud was established ‚Äì with a focus on helping customers leverage public cloud infrastructure and DevOps. Growth skyrockets.\\nEsa Kunninen appointed as the first Nordcloud CEO.\\n2013One of our original founders, Pyry Lehdonvirta, becomes a published author with HTML5 as an Application, a go-to resource for application designers and developers ‚Äì cementing our position as a pioneer in emerging technologies.\\nNordcloud expands into its second country: Sweden.\\n2014Growth gets serious as Nordcloud joins the 2-year EIT Digital Accelerator to kickstart European expansion.\\nNordcloud becomes an AWS Premier Consulting partner.\\nExpansion continues, with new Nordcloud offices in Denmark and the UK.\\n2015We seize a leadership position in the cloud application design and development space by creating a living style guide, a predecessor of modern design systems.\\nNordcloud secures ‚Ç¨1 million funding from Finnvera, the Finnish public financing company, to help drive expansion. We open new offices in Norway and Germany.\\nAs one of the world‚Äôs first AWS Lambda partners, we start delivering web-based applications based on cloud-native, serverless architectures.\\n2016Nordcloud enters the Netherlands.\\n2017Nordcloud is recognised in Gartner‚Äôs first-ever Magic Quadrant for Public Cloud Infrastructure Managed Service Providers, with Gartner particularly highlighting our multi-cloud expertise.\\nWe open our first office in Poland.\\n2018Microsoft names Nordcloud a finalist for Partner of the Year.\\nFor the second year running, Nordcloud is recognised in Gartner‚Äôs Magic Quadrant for Public Cloud Infrastructure Professional and Managed Services.\\nSwitzerland becomes the ninth country with a Nordcloud presence.\\n2019Microsoft names us Partner of the Year.\\nThe Financial Times names us as one of the 1,000 fastest-growing companies in Europe as part of its FT1000 ranking.\\nWe open an office in Austria, giving us a presence in 10 countries.\\n2020Gartner names Nordcloud the top cloud-native managed services provider in its Magic Quadrant for Public Cloud Infrastructure, Professional and Managed Services, Worldwide.\\nNordcloud achieves Google Cloud specialisations in cloud migration and training.\\nMicrosoft names us Partner of the Year.\\nIBM acquires Nordcloud, giving us new superpowers and scale for bringing cloud-native expertise to enterprise customers.\\n2021We officially launch Nordcloud Klarity, our cloud management and FinOps SaaS product. We originally developed it for our own managed services team, but based on popular demand, made it generally available for people looking to get more automation, visibility and cost control with their clouds.\\nMicrosoft names us Azure Infra Modernisation Partner of the Year.\\nAWS names us AWS Migration Partner of the Year.\\nNordcloud achieves VMware Master Services Competency in VMware Cloud on AWS, making us one of the rare partners to have such high credentials across both VMware and AWS.\\nNordcloud achieves a Google Cloud specialisation in infrastructure services.\\nGartner recognises Nordcloud as a Visionary in its Magic Quadrant for Public Cloud IT Transformation Services.\\nNordcloud becomes a signatory of Microsoft‚Äôs Partner Pledge, which is a commitment to helping people use technology in the right way and for the greater good.\\nNordcloud is recognised as a Great Place to Work in Austria, Denmark, Finland, Germany, Netherlands, Poland and the UK.\\n2022Nordcloud wins a major cloud agreement with Valtori, the IT arm of the Finnish government. This cloud partnership will help the government move faster towards cloud while maintaining robust security and data protection.\\nWe hit 1000 AWS certifications and receive an AWS Partner Network (APN) Certification Distinction.\\nWe hit 1000 Microsoft certifications.\\n2023Nordcloud‚Äôs founder and CEO Fernando Herrera steps down after a decade of leading the company. Jan Kritz, formerly COO, steps up to lead Nordcloud as CEO in an exciting new chapter.\\nNordcloud has been chosen by Microsoft as Western Europe Partner of the Year for Azure cloud solutions.\\n2024Nordcloud continues to drive innovation in cloud, enabling AI excellence in public cloud and revolutionising the automation of Platform Engineering Services.\\n \\n\\n\\n\\n\\nOur Offices. \\n\\n\\nAmsterdamNordcloud B.V. Netherlands\\nJohan Huizingalaan 765\\n1066 VH Amsterdam, NetherlandsShow routeBarcelonaVIEWNEXT\\nCarrer Jes√∫s Serra Santamans, 4\\n08174 Sant Cugat del Vall√®s, BarcelonaShow routeBerlinSpaces c/o Nordcloud Germany GmbH\\nJ√§gerstra√üe 54-55\\n10117 BerlinShow routeBernNordcloud Switzerland GmbH\\nZentroom\\nBahnhofplatz 10b\\n3011 BernShow routeCopenhagenNordcloud ApS Denmark\\nAmager F√¶lledvej 106\\n2300 K√∏benhavn SShow routeGothenburgNordcloud Hosting Sweden AB\\nJohann Willins Gata 8\\n416 64 G√∂teborg\\n(Johan Willins Gata 6 for visits and post)Show routeHelsinkiNordcloud Oy\\nPohjoisesplanadi 37A\\n00100 HelsinkiShow routeJyv√§skyl√§Nordcloud Oy\\nVapaudenkatu 60\\n40100 Jyv√§skyl√§Show routeJ√∂nk√∂pingNordcloud Hosting Sweden AB\\n√ñstra Storgatan 9\\n553 20 J√∂nk√∂pingShow routeKuopioNordcloud Oy\\nMicrokatu 1 (M)\\n70150 Kuopio (Novapolis)Show routeLondonIBM United Kingdom Ltd\\n20 York Road\\nLondon SE1 7NDShow routeMadridVIEWNEXT\\nAv. de Burgos, 8-A\\n28036 MadridShow routeMalm√∂Nordcloud Hosting Sweden AB\\nStortorget 11\\n211 22 Malm√∂Show routeManchesterNordcloud Ltd\\nHana, Landmark, St Peter’s Square\\nManchester M1 4BPShow routeMunichNordcloud Deutschland GmbH (IBM)\\nMies-van-der-Rohe-Stra√üe 6\\nTower 1 / 28 OG\\n80807 M√ºnchenShow routeOsloNordcloud AS Norway\\nGrundingen 6\\n0250 OsloShow routeOuluNordcloud Oy\\nElektroniikkatie 13\\n90580 Oulu (Technopolis)Show routePozna≈ÑNordcloud sp z.o.o. Poland\\nKupiec Pozna≈Ñski, 5th floor\\nPlac Wiosny Lud√≥w 2\\n61-831 Pozna≈ÑShow routeSaloNordcloud Oy\\nSalo IoT Park Oy\\nJoensuunkatu 7\\n24100 SaloShow routeStockholmNordcloud Hosting Sweden AB\\nDrottninggatan 68, v√•n 5\\n111 21 StockholmShow routeViennaNordcloud, Austria\\nObere Donaustra√üe 95\\n1020 ViennaShow routeWarsawNordcloud sp z.o.o. Poland\\nMennica Legacy Tower\\nul. Prosta 20\\n00-850 WarsawShow routeWroc≈ÇawNordcloud sp z.o.o. Poland\\nSpaces Wroclavia\\nul. Sucha 3\\n50-086 Wroc≈ÇawShow routeZugNordcloud Switzerland GmbH\\nGrafenauweg 8\\n6300 ZugShow route \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGet in Touch.Let‚Äôs discuss how we can help with your cloud journey. Our experts are standing by to talk about your migration, modernisation, development and skills challenges.\\n \\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tIlja‚Äôs passion and tech knowledge help customers transform how they manage infrastructure and develop apps in cloud.\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\n\\n\\nIlja Summala\\nLinkedIn\\n\\nGroup CTO\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSign up to our newsletter.Hear unique professional insights direct from Nordcloud's cloud native experts on the latest developments in cloud.\\r\\nWant to see what's waiting for you in the Newsletter? Get the full scoop! \\n\\n\\n\\n\\n\\nIndustries\", metadata={'source': 'https://nordcloud.com/company/', 'title': 'About Us ‚Äì Cloud Services ‚Äì Nordcloud', 'description': 'Nordcloud is a European cloud leader featured in Gartner‚Äôs Magic Quadrant. Learn how we help with Microsoft Azure, AWS and Google Cloud.', 'language': 'en-GB'})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.get_relevant_documents(inputs2[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# chain_type = \"map_reduce\"\n",
    "# chain_type = \"stuff\"\n",
    "chain_type = \"refine\" \n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=chain_type,\n",
    "    retriever=retriever,\n",
    "    # combine_docs_chain_kwargs={'prompt': reduce_prompt_template},\n",
    "    # chain_type_kwargs={\"map_prompt\": map_prompt_template},\n",
    "    return_source_documents=True,\n",
    "    verbose=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'Can you tell me more about the company nordcloud in munich?',\n",
       " 'result': '',\n",
       " 'source_documents': [Document(page_content=\"Proud to be cloud native.\\n\\n\\n\\n\\n\\n\\n\\n\\nWhy NordcloudWe help you use the cloud to become stronger, fitter and faster.\\nLearn more \\n\\nOur ApproachWe empower your business to drive value, velocity and growth with the public cloud.\\nLearn more \\n\\n\\n\\n\\n\\nCompany Timeline. \\n\\n\\n\\n2006A cloud-native infrastructure and web application development company is born in Finland!\\n2011Nordcloud was established ‚Äì with a focus on helping customers leverage public cloud infrastructure and DevOps. Growth skyrockets.\\nEsa Kunninen appointed as the first Nordcloud CEO.\\n2013One of our original founders, Pyry Lehdonvirta, becomes a published author with HTML5 as an Application, a go-to resource for application designers and developers ‚Äì cementing our position as a pioneer in emerging technologies.\\nNordcloud expands into its second country: Sweden.\\n2014Growth gets serious as Nordcloud joins the 2-year EIT Digital Accelerator to kickstart European expansion.\\nNordcloud becomes an AWS Premier Consulting partner.\\nExpansion continues, with new Nordcloud offices in Denmark and the UK.\\n2015We seize a leadership position in the cloud application design and development space by creating a living style guide, a predecessor of modern design systems.\\nNordcloud secures ‚Ç¨1 million funding from Finnvera, the Finnish public financing company, to help drive expansion. We open new offices in Norway and Germany.\\nAs one of the world‚Äôs first AWS Lambda partners, we start delivering web-based applications based on cloud-native, serverless architectures.\\n2016Nordcloud enters the Netherlands.\\n2017Nordcloud is recognised in Gartner‚Äôs first-ever Magic Quadrant for Public Cloud Infrastructure Managed Service Providers, with Gartner particularly highlighting our multi-cloud expertise.\\nWe open our first office in Poland.\\n2018Microsoft names Nordcloud a finalist for Partner of the Year.\\nFor the second year running, Nordcloud is recognised in Gartner‚Äôs Magic Quadrant for Public Cloud Infrastructure Professional and Managed Services.\\nSwitzerland becomes the ninth country with a Nordcloud presence.\\n2019Microsoft names us Partner of the Year.\\nThe Financial Times names us as one of the 1,000 fastest-growing companies in Europe as part of its FT1000 ranking.\\nWe open an office in Austria, giving us a presence in 10 countries.\\n2020Gartner names Nordcloud the top cloud-native managed services provider in its Magic Quadrant for Public Cloud Infrastructure, Professional and Managed Services, Worldwide.\\nNordcloud achieves Google Cloud specialisations in cloud migration and training.\\nMicrosoft names us Partner of the Year.\\nIBM acquires Nordcloud, giving us new superpowers and scale for bringing cloud-native expertise to enterprise customers.\\n2021We officially launch Nordcloud Klarity, our cloud management and FinOps SaaS product. We originally developed it for our own managed services team, but based on popular demand, made it generally available for people looking to get more automation, visibility and cost control with their clouds.\\nMicrosoft names us Azure Infra Modernisation Partner of the Year.\\nAWS names us AWS Migration Partner of the Year.\\nNordcloud achieves VMware Master Services Competency in VMware Cloud on AWS, making us one of the rare partners to have such high credentials across both VMware and AWS.\\nNordcloud achieves a Google Cloud specialisation in infrastructure services.\\nGartner recognises Nordcloud as a Visionary in its Magic Quadrant for Public Cloud IT Transformation Services.\\nNordcloud becomes a signatory of Microsoft‚Äôs Partner Pledge, which is a commitment to helping people use technology in the right way and for the greater good.\\nNordcloud is recognised as a Great Place to Work in Austria, Denmark, Finland, Germany, Netherlands, Poland and the UK.\\n2022Nordcloud wins a major cloud agreement with Valtori, the IT arm of the Finnish government. This cloud partnership will help the government move faster towards cloud while maintaining robust security and data protection.\\nWe hit 1000 AWS certifications and receive an AWS Partner Network (APN) Certification Distinction.\\nWe hit 1000 Microsoft certifications.\\n2023Nordcloud‚Äôs founder and CEO Fernando Herrera steps down after a decade of leading the company. Jan Kritz, formerly COO, steps up to lead Nordcloud as CEO in an exciting new chapter.\\nNordcloud has been chosen by Microsoft as Western Europe Partner of the Year for Azure cloud solutions.\\n2024Nordcloud continues to drive innovation in cloud, enabling AI excellence in public cloud and revolutionising the automation of Platform Engineering Services.\\n \\n\\n\\n\\n\\nOur Offices. \\n\\n\\nAmsterdamNordcloud B.V. Netherlands\\nJohan Huizingalaan 765\\n1066 VH Amsterdam, NetherlandsShow routeBarcelonaVIEWNEXT\\nCarrer Jes√∫s Serra Santamans, 4\\n08174 Sant Cugat del Vall√®s, BarcelonaShow routeBerlinSpaces c/o Nordcloud Germany GmbH\\nJ√§gerstra√üe 54-55\\n10117 BerlinShow routeBernNordcloud Switzerland GmbH\\nZentroom\\nBahnhofplatz 10b\\n3011 BernShow routeCopenhagenNordcloud ApS Denmark\\nAmager F√¶lledvej 106\\n2300 K√∏benhavn SShow routeGothenburgNordcloud Hosting Sweden AB\\nJohann Willins Gata 8\\n416 64 G√∂teborg\\n(Johan Willins Gata 6 for visits and post)Show routeHelsinkiNordcloud Oy\\nPohjoisesplanadi 37A\\n00100 HelsinkiShow routeJyv√§skyl√§Nordcloud Oy\\nVapaudenkatu 60\\n40100 Jyv√§skyl√§Show routeJ√∂nk√∂pingNordcloud Hosting Sweden AB\\n√ñstra Storgatan 9\\n553 20 J√∂nk√∂pingShow routeKuopioNordcloud Oy\\nMicrokatu 1 (M)\\n70150 Kuopio (Novapolis)Show routeLondonIBM United Kingdom Ltd\\n20 York Road\\nLondon SE1 7NDShow routeMadridVIEWNEXT\\nAv. de Burgos, 8-A\\n28036 MadridShow routeMalm√∂Nordcloud Hosting Sweden AB\\nStortorget 11\\n211 22 Malm√∂Show routeManchesterNordcloud Ltd\\nHana, Landmark, St Peter’s Square\\nManchester M1 4BPShow routeMunichNordcloud Deutschland GmbH (IBM)\\nMies-van-der-Rohe-Stra√üe 6\\nTower 1 / 28 OG\\n80807 M√ºnchenShow routeOsloNordcloud AS Norway\\nGrundingen 6\\n0250 OsloShow routeOuluNordcloud Oy\\nElektroniikkatie 13\\n90580 Oulu (Technopolis)Show routePozna≈ÑNordcloud sp z.o.o. Poland\\nKupiec Pozna≈Ñski, 5th floor\\nPlac Wiosny Lud√≥w 2\\n61-831 Pozna≈ÑShow routeSaloNordcloud Oy\\nSalo IoT Park Oy\\nJoensuunkatu 7\\n24100 SaloShow routeStockholmNordcloud Hosting Sweden AB\\nDrottninggatan 68, v√•n 5\\n111 21 StockholmShow routeViennaNordcloud, Austria\\nObere Donaustra√üe 95\\n1020 ViennaShow routeWarsawNordcloud sp z.o.o. Poland\\nMennica Legacy Tower\\nul. Prosta 20\\n00-850 WarsawShow routeWroc≈ÇawNordcloud sp z.o.o. Poland\\nSpaces Wroclavia\\nul. Sucha 3\\n50-086 Wroc≈ÇawShow routeZugNordcloud Switzerland GmbH\\nGrafenauweg 8\\n6300 ZugShow route \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGet in Touch.Let‚Äôs discuss how we can help with your cloud journey. Our experts are standing by to talk about your migration, modernisation, development and skills challenges.\\n \\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tIlja‚Äôs passion and tech knowledge help customers transform how they manage infrastructure and develop apps in cloud.\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\n\\n\\nIlja Summala\\nLinkedIn\\n\\nGroup CTO\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSign up to our newsletter.Hear unique professional insights direct from Nordcloud's cloud native experts on the latest developments in cloud.\\r\\nWant to see what's waiting for you in the Newsletter? Get the full scoop! \\n\\n\\n\\n\\n\\nIndustries\", metadata={'source': 'https://nordcloud.com/company/', 'title': 'About Us ‚Äì Cloud Services ‚Äì Nordcloud', 'description': 'Nordcloud is a European cloud leader featured in Gartner‚Äôs Magic Quadrant. Learn how we help with Microsoft Azure, AWS and Google Cloud.', 'language': 'en-GB'}),\n",
       "  Document(page_content='Petteri Uljas\\nNCEE Sales\\nPetteri began his career as a software developer and has ascended through global leadership roles and board positions across multiple countries, within Capgemini and Tietoevry. His passion lies in achieving objectives through people, forging cohesive teams from diverse professional and cultural mixes, and fostering trust that sees results for both us and our customers. Petteri believes that there’s no cloud without people.\\n\\n\\n\\n\\n  \\nScott Eivers\\nUK Sales\\nScott brings a wealth of experience at building successful services businesses in the technology sector into Nordcloud. Prior to Nordcloud Scott has led a variety of growth roles including most recently building the business consulting team of Gartner in EMEA.His role today is to lead the UK region, driving growth through the multiple sales and commercial routes. This builds upon his previous role at Nordcloud as the Chief Growth Officer where he had responsibility for building various growth acceleration initiatives including marketing, product mgmt, commercial mgmt and corporate development\\n\\n\\n\\n\\n  \\nThomas Baus\\nDACH Sales\\nHaving been part of Nordcloud for most of the company‚Äôs lifespan, Thomas has dedicated heart and mind to nurturing our brand, expanding our customer base, fostering our team, and enriching our culture within our German-speaking regions. After holding various global positions, he now returns to focus on our ongoing growth and success journey in the DACH region.\\n\\n\\n\\n\\n  \\nNilay Mardikar\\nMigrations\\nStarting his career as a software developer, Nilay has been in the IT realm since 1994, having worked for the likes of Atos, Tietoevry, Capgemini, and Birlasoft previously. He‚Äôs committed to working closely with clients to define cloud success. Extensive experience in sales, solutions and delivery helps Nilay support individuals in various teams to thrive. In his current role, Our ambition is to broaden migration and post migration modernization delivery to foster growth, reliability, predictability with reuse and profitability for Nordcloud and IBM. Nilay has strong experience in critical delivery and sales, solutions roles including strategic engagements with different customers in Nordics, EMEA.\\n\\n\\n\\n\\n  \\nIndrayudh Ghosh\\nPlatform Engineering Services\\nIndra brings extensive experience in sales and delivery across Europe, Asia, and the Americas. As a tech evangelist and growth-oriented professional, Indra specializes in orchestrating large end-to-end deliveries while maintaining a steadfast focus on people. In the constantly evolving tech landscape, Indra spearheads the expansion of Nordcloud‚Äôs platform engineering services through AI and automation, driven by the collective efforts of our people.\\n\\n\\n\\n\\n  \\nJaana Salmela\\nProfessional Services\\nHaving held numerous leadership roles at both global and regional levels, Jaana has played a pivotal role in shaping and enhancing Nordcloud‚Äôs delivery culture and quality. With a robust background in managing enterprise-grade IT service teams and consulting organisations, she is tasked with scaling and enhancing our global professional services teams and offerings to meet the evolving demands of our key markets.\\n\\n\\n\\n\\n  \\nIlja Summala\\nGroup CTO\\nIlja is a legend in the tech industry. After 12 years at tech giant Nokia, he joined Nordcloud as CTO in 2012 to lead us on our journey to become a full-stack, cloud-native system integrator. His passion and unparalleled technological skills help customers transform the way they manage infrastructure and develop applications in a cloud-native world.\\n\\n\\n\\n\\n  \\nMaria Ihamuotila\\nChief of Staff\\nBringing expertise in strategy consulting, international expansion, and operational project management within dynamic, high-growth environments, Maria spearheads the development of Nordcloud’s group strategy and operations. She is driven by a passion for multidisciplinary topics and excels in translating strategy into actionable plans through clear communication, robust cross-functional collaboration, and data-driven problem-solving.\\n\\n\\n\\n\\n  \\nTuomas Toropainen\\nCFO Office\\nTuomas is our numbers guy. With a finance career spanning a wide range of industries, he‚Äôs on a mission to challenge traditional perceptions of finance leaders. Like Nordcloud, he‚Äôs forward-thinking, and the words ‚ÄòBut that‚Äôs how we‚Äôve always done it!‚Äô will never leave his mouth.\\n\\n\\n\\n\\n  \\nRam Kumar\\nChief People Officer\\nCustomer value focus\\nHow do you make great things happen in the cloud? By having a crack team of cloud ninjas leading and supporting you. Which is where Ram comes in. He has the perfect combination of cloud/tech and HR experience, honed over decades working with the likes of IBM, Wipro, Nokia, Microsoft and Cloudator. His leadership helps ensure our customers and our colleagues benefit from strategies, processes and development opportunities that put them at the cutting edge of cloud.\\nTalent focus\\nOur purpose as a company is to accelerate the world to a more equal, greener and sustainable digital society. And that requires a team of uniquely talented people working together to achieve greatness. That‚Äôs where Ram comes in. He helps us build and nurture our team of digital builders born in the cloud ‚Äì drawing on deep cloud/tech and people experience honed over decades working with the likes of IBM, Wipro, Nokia, Microsoft and Cloudator.¬†\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nProud to be cloud native.\\n\\n\\n\\n\\n\\n\\n\\n\\nWhy NordcloudWe help you use the cloud to become stronger, fitter and faster.\\nLearn more \\n\\nOur ApproachWe empower your business to drive value, velocity and growth with the public cloud.\\nLearn more \\n\\n\\n\\n\\n\\nCompany Timeline.', metadata={'source': 'https://nordcloud.com/company/', 'title': 'About Us ‚Äì Cloud Services ‚Äì Nordcloud', 'description': 'Nordcloud is a European cloud leader featured in Gartner‚Äôs Magic Quadrant. Learn how we help with Microsoft Azure, AWS and Google Cloud.', 'language': 'en-GB'}),\n",
       "  Document(page_content=\"Get in Touch.Let‚Äôs discuss how we can help with your cloud journey. Our experts are standing by to talk about your migration, modernisation, development and skills challenges.\\n \\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tIlja‚Äôs passion and tech knowledge help customers transform how they manage infrastructure and develop apps in cloud.\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\n\\n\\nIlja Summala\\nLinkedIn\\n\\nGroup CTO\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSign up to our newsletter.Hear unique professional insights direct from Nordcloud's cloud native experts on the latest developments in cloud.\\r\\nWant to see what's waiting for you in the Newsletter? Get the full scoop! \\n\\n\\n\\n\\n\\nIndustries\\n\\nAutomotive\\nAviation\\nHealthcare\\nFinancial Services & Insurance\\nManufacturing & Industrial\\nPublic Sector\\nServices\\nTechnology & ISVs\\n\\n\\nPartners\\n\\nAmazon Web Services\\nMicrosoft Azure\\nGoogle Cloud\\nSAP\\nIBM Multicloud\\n\\n\\nCompany\\n\\nContact\\nCareers\\nAbout Us\\nOur Offices\\nPress Office\\nCommunity & Culture\\nInvestors\\n\\n\\nPolicies\\n\\nPrivacy Notice\\nRecruitment Privacy Policy\\nESG Policy Statement\\nQuality Policy\\nFeedback\\nSecurity\\nCookies\\nCookie Settings\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\nInstagram\\nTwitter\\nFacebook\\nLinkedin\", metadata={'source': 'https://nordcloud.com/company/', 'title': 'About Us ‚Äì Cloud Services ‚Äì Nordcloud', 'description': 'Nordcloud is a European cloud leader featured in Gartner‚Äôs Magic Quadrant. Learn how we help with Microsoft Azure, AWS and Google Cloud.', 'language': 'en-GB'}),\n",
       "  Document(page_content='About Us ‚Äì Cloud Services ‚Äì Nordcloud\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to content\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nServices\\n\\nCloud Strategy\\n\\nCloud¬†Transformation\\n\\nCloud Transformation¬†Strategy\\nOrganisation (CCoE)¬†Design\\nCloud Transformation¬†Consulting\\nSustainability in the Cloud\\n\\n\\nCloud¬†Training\\n\\nGeneral Cloud¬†Courses\\nAWS Cloud¬†Courses\\nAzure Cloud¬†Training\\nGoogle Cloud¬†Courses\\nFinOps¬†Courses\\n\\n\\n\\n\\nCloud Foundation & Migration\\n\\nCloud¬†Foundations\\n\\nBuild Your Cloud¬†Foundations\\nCloud Upskilling\\n\\n\\nCloud¬†Migration\\n\\nStart your migration¬†journey\\nMigrate to the¬†Cloud\\nManaged Cloud¬†Migration\\n\\n\\nCloud Security\\n\\nSecurity & Compliance\\n\\n\\n\\n\\nInnovation & Modernisation\\n\\nAI &¬†Data\\n\\nGenerative AI\\nData & AI¬†Strategy\\nData Migration &¬†Modernisation\\nAI & Machine Learning¬†Industrialisation\\nAI & Machine Learning at the¬†Edge\\nBusiness Intelligence & Data¬†Visualisation\\n\\n\\nPlatform and App modernisation\\n\\nModernise Applications to the¬†Cloud\\nFrictionless Delivery of¬†Software\\n\\n\\nCloud Native Build\\n\\nApplication¬†Development\\nDigital¬†Design\\n\\n\\nCloud DevOps\\n\\nDevOps Foundation\\nKubernetes\\n\\n\\n\\n\\nManaged Services\\n\\nManaged Cloud¬†Services\\n\\nManaged Cloud¬†Foundations\\nManaged¬†Databases\\nManaged Cloud¬†Environments\\nManaged App Modernisation\\nPES Automation¬†Platform\\n\\n\\nCloud PaaS Management\\n\\nApplication¬†Management\\nSAP¬†Operation¬†\\n\\n\\nFinOps\\n\\nManaged¬†FinOps\\nFinOps¬†Courses\\n\\n\\n\\n\\nAll Services\\nGen AI in the cloud? Start hereAll the support you need to use gen AI and LLMs efficiently and securely \\uf8ffüëáGenerative AI With Public Cloud\\n\\n\\nPartners\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAmazon Web¬†Services\\n\\nAmazon Web¬†Services\\nAWS Services\\n\\nAWS Migration\\nAWS Data &¬†Analytics\\nAWS Cloud¬†Operations\\nAWS Managed Cloud¬†Services\\nTransforming Businesses into¬†SaaS\\nAWS Security¬†Services\\n\\n\\nAWS Solutions\\n\\nAWS ClearStart\\nAWS End User¬†Computing\\nAWS¬†Outposts\\nAWS Marketplace\\nMicrosoft on¬†AWS\\nRunning Containers on¬†AWS\\nVMware Cloud on¬†AWS\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMicrosoft¬†Azure\\n\\nMicrosoft¬†Azure\\n\\nData and AI\\nInfrastructure and migration\\nSecurity\\nManaged services\\nDigital and application innovation\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGoogle¬†Cloud\\n\\nGoogle¬†Cloud\\nGoogle Cloud Services\\n\\nGoogle Cloud Managed Cloud¬†Services\\nMigrating to Cloud with Google¬†Cloud\\nGoogle Cloud Application¬†Modernisation\\nUnlock your data with Google¬†Cloud\\n\\n\\nGoogle Cloud Solutions\\n\\nGoogle Cloud VMware¬†Engine\\nGoogle Workspace\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSAP\\n\\nSAP\\n\\nSAP Cloud Advisory\\nSAP Cloud¬†Migration¬†\\nSAP¬†Operation¬†\\nSAP¬†Automation¬†\\nSAP¬†Innovation\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nIBM¬†Multicloud\\n\\nIBM¬†Multicloud\\n\\nIBM Multicloud¬†Accelerator\\nIBM Multicloud¬†Provisioning\\nIBM Multicloud Machine Image¬†Toolkit\\nIBM Multicloud¬†Autobackup\\nIBM Multicloud¬†Autopatcher\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nRed Hat¬†OpenShift\\nAll Partners\\n7 lessons from battle-hardened cloud adoptersMore details\\n\\n\\nIndustries\\n\\nAutomotive\\n\\t\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAutomotive\\n\\nBuckle your seatbelt, and enjoy the cloud journey.\\n\\n\\nAviation\\n\\t\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAviation\\n\\nDon‚Äôt be grounded in the data centre‚Äì fly to the cloud.\\n\\n\\nFinancial Services\\n\\t\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFinancial Services\\n\\nTick the boxes: agility, security, scalability and cost efficiency.\\n\\n\\nHealthcare\\n\\t\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nHealthcare\\n\\nDeliver cloud solutions for patients and clinicians.\\n\\n\\nManufacturing\\n\\t\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nManufacturing\\n\\nInnovation engine that boosts efficiency and productivity.\\n\\n\\nPublic¬†Sector\\n\\t\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPublic¬†Sector\\n\\nEmpowering governments to meet citizens‚Äô expectations.\\n\\n\\nServices\\n\\t\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nServices\\n\\nImproving efficiency and reducing costs.\\n\\n\\nTechnology &¬†ISVs\\n\\t\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTechnology &¬†ISVs\\n\\nTransform on-premises solutions to SaaS.\\n\\n\\nAll Industries\\n\\t\\t\\t\\t\\n\\nAll Industries\\n\\nTailored solutions for every industry sector.\\n\\n\\nInteractive Route Map: Aviation’s Flight PlanMore details\\n\\n\\nContent¬†Hub\\n\\nLatest postsThe Gen AI adoption roadmap\\uf8ffüèÜ Top companies get to enjoy this sequel | Cloud CoreIT ops headaches you don‚Äôt have to live with\\nTrending contentIT ops headaches you don‚Äôt have to live withHow to cure Day 2 digital transformation challengesGenerative AI 101: The basics and how public cloud fits in\\nBy formatAll formatsPostsCase StudiesGuidesVideosInfographicsTech CommunityNewslettersPodcasts\\nHow to cure Day 2 digital transformation challengesGet your free guideMore details\\n\\n\\nCase¬†Studies\\nEvents\\nCareers\\nAbout¬†Us\\n \\nContact Us\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nContact Us\\n\\n\\n\\n\\n\\n\\nHome > About Us\\n\\n\\n\\n\\nAbout Us.Nordcloud is a European leader in cloud implementation, application development, managed services and training. We‚Äôre triple certified and featured in Gartner‚Äôs Magic Quadrant.\\nGet in Touch \\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\nCompany Numbers. \\n\\n>45%Net revenue growth year on year\\n \\n\\n1,000+Public cloud implementations\\n \\n\\n1,300+Team members\\n \\n\\n200+Enterprise clients\\n \\n\\n10Countries with Nordcloud offices\\n \\n\\n\\n\\n\\n\\nLeadership Team. \\n\\n\\n  \\nJan Kritz\\nGroup CEO\\nJan‚Äôs unique combo of cloud-first expertise and positive leadership style makes him the perfect leader for Nordcloud. Together with his team of cloud ninjas, Jan supports customers at every step of their journey, helping them harness the power of an agile, cloud-native approach. Having previously held senior leadership positions at Capgemini and Atos among others, in his 5+ years at Nordcloud, he‚Äôs overseen our growth as we‚Äôve cemented our position as Europe‚Äôs leading cloud-native partner.\\n\\n\\n\\n\\n  \\nMagnus Manders\\nHead of Service Lines\\nAfter working with Nordcloud as Group CTO at Nordea, Magnus knew he wanted to be part of our journey. With a career spanning 20 years at global giants like IKEA and Capgemini,¬† Magnus now spends his days helping customers overcome any and all barriers to cloud adoption so they achieve both quick wins and sustainable value.\\nRead more about Magnus‚Äô experience, approach and view on cloud ¬ª\\n\\n\\n\\n\\n  \\nTapio Koskinen\\nGlobal Sales & Marketing\\nWant a cloud-native tech whiz who truly understands things from the customer‚Äôs side of the table? Tapio‚Äôs your guy. As our Global Sales Lead, he‚Äôs all about getting the right solutions and services to the right people, so everyone from directors to devs benefit from everything the public cloud has to offer. Certified in AWS and experienced in Azure and Google Cloud Platform, Tapio, along with his global team, give you impartial advice grounded in cloud-native experience.\\n\\n\\n\\n\\n  \\nNiko Mykk√§nen\\nAlliances\\nWe‚Äôre all about the power of collaboration at Nordcloud, which is why Niko plays such an important role. He‚Äôs the strategic link between our hyperscaler and technology partners, customers and internal teams ‚Äì helping everyone drive more growth and innovation from public cloud capabilities. His impressive career has spanned leadership roles at AWS and Nokia, and he has a particular interest in AI and predictive analytics.\\n\\n\\n\\n\\n  \\nPetteri Uljas\\nNCEE Sales\\nPetteri began his career as a software developer and has ascended through global leadership roles and board positions across multiple countries, within Capgemini and Tietoevry. His passion lies in achieving objectives through people, forging cohesive teams from diverse professional and cultural mixes, and fostering trust that sees results for both us and our customers. Petteri believes that there’s no cloud without people.\\n\\n\\n\\n\\n  \\nScott Eivers\\nUK Sales\\nScott brings a wealth of experience at building successful services businesses in the technology sector into Nordcloud. Prior to Nordcloud Scott has led a variety of growth roles including most recently building the business consulting team of Gartner in EMEA.His role today is to lead the UK region, driving growth through the multiple sales and commercial routes. This builds upon his previous role at Nordcloud as the Chief Growth Officer where he had responsibility for building various growth acceleration initiatives including marketing, product mgmt, commercial mgmt and corporate development', metadata={'source': 'https://nordcloud.com/company/', 'title': 'About Us ‚Äì Cloud Services ‚Äì Nordcloud', 'description': 'Nordcloud is a European cloud leader featured in Gartner‚Äôs Magic Quadrant. Learn how we help with Microsoft Azure, AWS and Google Cloud.', 'language': 'en-GB'})]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import langchain\n",
    "\n",
    "query = inputs2[0]\n",
    "# langchain.debug = True\n",
    "qa.invoke({\"query\": query})\n",
    "# langchain.debug = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools\n",
    "* https://github.com/langchain-ai/langchain/issues/14954#issuecomment-1864918697\n",
    "* https://github.com/langchain-ai/langchain/issues/14954#issuecomment-1876906769"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool\n",
    "\n",
    "# tools = [\n",
    "#     Tool(\n",
    "#         name='Knowledge Base',\n",
    "#         func=qa.invoke,\n",
    "#         # func=qa.invoke,\n",
    "#         description=(\n",
    "#             'use this tool when answering general knowledge queries to get '\n",
    "#             'more information about the topic'\n",
    "#         )\n",
    "#     )\n",
    "# ]\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name='northcloud_search',\n",
    "        func=qa.invoke,\n",
    "        description=(\n",
    "            'Search for information about NorthCloud. '\n",
    "            'For any questions about NorthCloud, you must use this tool!'\n",
    "        )\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yingding/VENV/agents3.11/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.agents import AgentType \n",
    "\n",
    "agent = initialize_agent(\n",
    "    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    max_iterations=3,\n",
    "    output_key = \"result\",\n",
    "    handle_parsing_errors=True,\n",
    "    early_stopping_method='generate',\n",
    "    memory = ConversationBufferMemory(memory_key = 'chat_history')   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mCould not parse LLM output: ``\u001b[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001b[32;1m\u001b[1;3mCould not parse LLM output: ``\u001b[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001b[32;1m\u001b[1;3mCould not parse LLM output: ``\u001b[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:"
     ]
    },
    {
     "ename": "OutputParserException",
     "evalue": "Could not parse LLM output: ``",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs2\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/VENV/agents3.11/lib/python3.11/site-packages/langchain/chains/base.py:163\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    162\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    164\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m~/VENV/agents3.11/lib/python3.11/site-packages/langchain/chains/base.py:153\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    152\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 153\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    156\u001b[0m     )\n\u001b[1;32m    158\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    159\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    160\u001b[0m     )\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/VENV/agents3.11/lib/python3.11/site-packages/langchain/agents/agent.py:1455\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m   1453\u001b[0m     iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1454\u001b[0m     time_elapsed \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[0;32m-> 1455\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_stopped_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1456\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stopping_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m   1457\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return(output, intermediate_steps, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n",
      "File \u001b[0;32m~/VENV/agents3.11/lib/python3.11/site-packages/langchain/agents/agent.py:868\u001b[0m, in \u001b[0;36mAgent.return_stopped_response\u001b[0;34m(self, early_stopping_method, intermediate_steps, **kwargs)\u001b[0m\n\u001b[1;32m    866\u001b[0m full_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_chain\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfull_inputs)\n\u001b[1;32m    867\u001b[0m \u001b[38;5;66;03m# We try to extract a final answer\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m parsed_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(parsed_output, AgentFinish):\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# If we can extract, we send the correct stuff\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_output\n",
      "File \u001b[0;32m~/VENV/agents3.11/lib/python3.11/site-packages/langchain/agents/conversational/output_parser.py:32\u001b[0m, in \u001b[0;36mConvoOutputParser.parse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     30\u001b[0m match \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msearch(regex, text, re\u001b[38;5;241m.\u001b[39mDOTALL)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m match:\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not parse LLM output: `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     33\u001b[0m action \u001b[38;5;241m=\u001b[39m match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     34\u001b[0m action_input \u001b[38;5;241m=\u001b[39m match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mOutputParserException\u001b[0m: Could not parse LLM output: ``"
     ]
    }
   ],
   "source": [
    "agent.invoke({\"input\": inputs2[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.agents import AgentExecutor\n",
    "# https://github.com/langchain-ai/langchain/issues/14954#issuecomment-1864918697\n",
    "# agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, return_intermediate_steps=False, handle_parsing_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent_executor.invoke({\"input\": inputs2[0]})\n",
    "# agent_executor.invoke({\"input\": \"hi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEAR_MEMORY = False\n",
    "# CLEAR_MEMORY = True\n",
    "\n",
    "if CLEAR_MEMORY:\n",
    "    clear_mps_memory(tokenizer=tokenizer, generator=generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
